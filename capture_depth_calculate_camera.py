from pathlib import Path
import numpy as np
import json
from collections import Counter
import open3d as o3d

import os
import numpy as np

def look_at_rotation(camera_pos, target_pos, up_vector=np.array([0, 0, 1])):
    """
    ç”Ÿæˆ Blender ç”¨çš„æ¬§æ‹‰è§’ (XYZ é¡ºåº)ï¼Œä½¿ç›¸æœºä» camera_pos çœ‹å‘ target_posã€‚
    """
    from scipy.spatial.transform import Rotation as R

    forward = np.array(target_pos) - np.array(camera_pos)
    forward /= np.linalg.norm(forward)

    right = np.cross(up_vector, forward)
    right /= np.linalg.norm(right)

    up = np.cross(forward, right)
    up /= np.linalg.norm(up)

    # æ³¨æ„ forward è¦å–è´Ÿä»¥ç¬¦åˆ Blender ç›¸æœº -Z çœ‹å‘ç›®æ ‡
    rot_matrix = np.stack([right, up, -forward], axis=1)

    r = R.from_matrix(rot_matrix)
    return r.as_euler('xyz', degrees=False)




def compute_valid_camera_distance(center, direction, original_camera_pos):
    """
    æ²¿ç»™å®šæ–¹å‘ä» center å‡ºå‘ï¼Œè®¡ç®—åœ¨ä¸ç©¿åœ°ã€ä¸è¶…å¤©èŠ±ã€ä¸è¶…è·ç¦»çš„çº¦æŸä¸‹çš„æœ€å¤§åˆæ³•ç›¸æœºè·ç¦» tã€‚
    
    é™åˆ¶ï¼š
    - ç›¸æœº z å¿…é¡»åœ¨ [0, 1.5 * original_camera_z] èŒƒå›´å†…
    - ç›¸æœºè·ç¦»ä¸èƒ½è¶…è¿‡ r0ï¼ˆåŸå§‹ç›¸æœºä¸ä¸­å¿ƒç‚¹çš„è·ç¦»ï¼‰
    
    è¿”å›ï¼š
    - åˆæ³•è·ç¦» tï¼ˆfloatï¼‰
    """
    cz = center[2]
    dz = direction[2]
    z0 = original_camera_pos[2]
    r0 = np.linalg.norm(center - original_camera_pos)

    t_candidates = []

    # åœ°æ¿é™åˆ¶
    if dz < 0:
        t_floor = (0 - cz) / dz
        if t_floor > 0:
            t_candidates.append(t_floor)

    # å¤©èŠ±æ¿é™åˆ¶
    if dz > 0:
        t_ceiling = (1.5 * z0 - cz) / dz
        if t_ceiling > 0:
            t_candidates.append(t_ceiling)

    # è·ç¦»é™åˆ¶
    t_candidates.append(r0)

    if not t_candidates or min(t_candidates) <= 0:
        return None  # è¡¨ç¤ºè¯¥æ–¹å‘å®Œå…¨éæ³•

    return min(t_candidates)



def generate_layered_directions(base_direction, angle_deg, num_directions):
    """
    åœ¨ä»¥ base_direction ä¸ºä¸­å¿ƒçš„çƒé¢é”¥ä½“ï¼ˆå¤¹è§’ angle_degï¼‰ä¸Šå‡åŒ€é‡‡æ ·æ–¹å‘å‘é‡ã€‚
    è¿”å›å•ä½å‘é‡åˆ—è¡¨ï¼Œé•¿åº¦ä¸º num_directionsã€‚
    """
    base_direction = base_direction / np.linalg.norm(base_direction)
    directions = []

    # æ‰¾ä¸€ä¸ªä¸ base_direction ä¸å…±çº¿çš„å‘é‡
    if abs(base_direction[2]) < 0.99:
        ortho = np.array([0, 0, 1])
    else:
        ortho = np.array([0, 1, 0])

    # æ„é€ æ­£äº¤åŸºåº•
    u = np.cross(base_direction, ortho)
    u /= np.linalg.norm(u)
    v = np.cross(base_direction, u)

    # çƒé¢é”¥ä½“é‡‡æ ·
    angle_rad = np.radians(angle_deg)
    for i in range(num_directions):
        theta = 2 * np.pi * i / num_directions
        direction = (
            np.cos(angle_rad) * base_direction +
            np.sin(angle_rad) * (np.cos(theta) * u + np.sin(theta) * v)
        )
        direction /= np.linalg.norm(direction)
        directions.append(direction)

    return directions

def generate_fine_directions(found_angle_deg, angle_step_deg, base_direction, num=24):
    """
    æ ¹æ®å¤–å±‚æ‰¾åˆ°åˆæ³•æ–¹å‘çš„å¤¹è§’ found_angle_deg å’Œæ­¥è¿›è§’ angle_step_degï¼Œ
    è‡ªåŠ¨å›é€€ä¸€åœˆè§’åº¦å¹¶åœ¨è¯¥å¤¹è§’ä¸Šä»¥ base_direction ä¸ºä¸­å¿ƒç”Ÿæˆ num ä¸ªæ–¹å‘ã€‚
    
    ç¤ºä¾‹ï¼šè‹¥åœ¨ 45Â° å±‚æ‰¾åˆ°åˆæ³•è§†è§’ï¼Œæ­¥è¿›ä¸º 15Â°ï¼Œåˆ™å›é€€è‡³ 30Â° åšç²¾ç»†é‡‡æ ·ã€‚
    """
    refine_angle = found_angle_deg - angle_step_deg
    if refine_angle <= 0:
        # é˜²å¾¡ï¼šå¦‚æœå·²ç»æ˜¯æœ€å†…åœˆï¼Œä¸å†å›é€€ï¼Œä½¿ç”¨å½“å‰è§’åº¦
        refine_angle = found_angle_deg
    return generate_layered_directions(base_direction, refine_angle, num_directions=num)



def save_blender_camera_position(view_result, save_dir, idx):
    """
    ä¿å­˜ Blender ç›¸æœºä½ç½®å’Œæœå‘å‘é‡ï¼ˆæ¥è‡ªè§†è§’æœç´¢ç»“æœï¼‰ã€‚

    å‚æ•°:
        view_result: åŒ…å« 'location' å’Œ 'rotation_euler' çš„å­—å…¸
        save_dir: ä¿å­˜ç›®å½•
        idx: å½“å‰ç›¸æœºç¼–å·
    """
    data = {
        "position": view_result["location"],
        "rotation_euler": view_result["rotation_euler"]
    }

    os.makedirs(save_dir, exist_ok=True)
    save_path = Path(save_dir) / f"camera_{idx:02d}.json"
    with open(save_path, 'w') as f:
        json.dump(data, f, indent=4)

    print(f"ğŸ“¸ ä¿å­˜ Blender ç›¸æœºä½ç½®åˆ°: {save_path}")


def estimate_radius_from_pointcloud(pcd, factor=2.0):
    import numpy as np
    import open3d as o3d

    pcd_tree = o3d.geometry.KDTreeFlann(pcd)
    points = np.asarray(pcd.points)
    min_dist = np.inf

    for i in range(len(points)):
        [_, idx, dist_sq] = pcd_tree.search_knn_vector_3d(points[i], 2)
        if len(dist_sq) >= 2:
            dist = np.sqrt(dist_sq[1])
            if dist > 0:
                min_dist = min(min_dist, dist)

    return factor * min_dist if np.isfinite(min_dist) else 0.1  # fallback


def ray_hits_kdtree(ray_origin, ray_target, kdtree, point_cloud, step=0.5, factor=2.0):
    import numpy as np

    radius = estimate_radius_from_pointcloud(point_cloud, factor=factor)
    ray_origin = np.array(ray_origin)
    ray_target = np.array(ray_target)
    direction = ray_target - ray_origin
    distance = np.linalg.norm(direction)
    if distance == 0:
        return False

    direction = direction / distance
    num_steps = int(distance / step)

    for i in range(1, num_steps + 1):
        point = ray_origin + i * step * direction
        [_, idx, _] = kdtree.search_radius_vector_3d(point, radius)
        if len(idx) > 0:
            return True

    return False

def open3d_to_blender_vec(v):
    # v: np.array([x, y, z]) from Open3D
    return np.array([v[0], -v[2], v[1]])

def estimate_unobserved_main_direction(unobserved_points, center, original_camera_pos):
    """
    åˆ©ç”¨ç‚¹æŠ•å½±åˆ°çƒé¢ã€ä¸åŸç›¸æœºè¿å¿ƒçº¿æ¯”è¾ƒæ–¹å‘ï¼Œè¿”å›å»ºè®®çš„è§‚å¯Ÿæ–¹å‘ï¼ˆå•ä½å‘é‡ï¼‰ã€‚
    """
    vectors = unobserved_points - center
    unit_vectors = vectors / np.linalg.norm(vectors, axis=1, keepdims=True)

    dir_mean = np.mean(unit_vectors, axis=0)
    dir_mean /= np.linalg.norm(dir_mean)

    ref_vec = original_camera_pos - center
    ref_vec /= np.linalg.norm(ref_vec)

    if np.dot(dir_mean, ref_vec) > 0:
        dir_mean = -dir_mean  # ç¿»è½¬æ–¹å‘ â¤ èµ°å¦ä¸€é¢å»è§‚å¯Ÿ

    return dir_mean
  

def find_best_viewpoint(
    unobserved_points,
    cloud_clean_pcd,
    target_pcd,
    original_camera_pos,
    angle_step_deg=15,
    max_angle_deg=135,
):
    """
    å¯»æ‰¾ä¸€ä¸ªåˆæ³•ä¸”å°½å¯èƒ½æ¥è¿‘ä¸»æ³•å‘çš„ç›¸æœºè§†è§’ï¼Œè¿”å› Blender å¯ç”¨çš„ä½å§¿ï¼ˆä½ç½® + æ¬§æ‹‰è§’ï¼‰ã€‚
    ä½¿ç”¨ç²—æ‰°åŠ¨ + ç²¾ç»†æ‰°åŠ¨ + fallback ä¸‰å±‚ç­–ç•¥ã€‚
    """

    cloud_clean_kdtree = o3d.geometry.KDTreeFlann(cloud_clean_pcd)
    target_kdtree = o3d.geometry.KDTreeFlann(target_pcd)

    center = np.mean(np.asarray(target_pcd.points), axis=0)
    z0 = original_camera_pos[2]

    normal_open3d = estimate_unobserved_main_direction(unobserved_points, center, original_camera_pos)

    # âœ… è½¬æ¢ä¸º Blender åæ ‡ç³»ä¸‹çš„æ–¹å‘å‘é‡
    normal_mean = open3d_to_blender_vec(normal_open3d)
    best_coarse_cam = None

    for angle_deg in range(angle_step_deg, max_angle_deg + 1, angle_step_deg):
        directions = generate_layered_directions(normal_mean, angle_deg, num_directions=4)

        for dir_vec in directions:
            t = compute_valid_camera_distance(center, dir_vec, original_camera_pos)
            if t is None:
                print(f"âŒ è·ç¦»å¤±è´¥: direction = {dir_vec}, angle = {angle_deg}")
                continue

            cam_pos = center + t * dir_vec
            if cam_pos[2] < 1e-2:
                cam_pos[2] = 1e-2
            if not (0 < cam_pos[2] < 1.5 * z0):
                continue


            blocked_by_env = ray_hits_kdtree(cam_pos, center, cloud_clean_kdtree, cloud_clean_pcd)
            # ç›¸æœºæ†å­æ˜¯å¦æ’åˆ°äº†åœ°é¢æˆ–å…¶ä»–ç¯å¢ƒéšœç¢
            rod_hits_env = ray_hits_kdtree(cam_pos, [cam_pos[0], cam_pos[1], 0], cloud_clean_kdtree, cloud_clean_pcd)

            if blocked_by_env or rod_hits_env:
                reason = []
                if blocked_by_env:
                    reason.append("âŒ ç¯å¢ƒé®æŒ¡")
                if rod_hits_env:
                    reason.append("âŒ ç›¸æœºæ†ç¢°æ’")
                print(f"âš ï¸ éæ³•è§†è§’: angle={angle_deg}Â°, pos={cam_pos.tolist()} | åŸå› : {', '.join(reason)}")
                continue

            best_coarse_cam = cam_pos

            refine_angle = angle_deg - angle_step_deg
            if refine_angle > 0:
                fine_dirs = generate_layered_directions(normal_mean, refine_angle, num_directions=24)

                for fine_dir in fine_dirs:
                    t_fine = compute_valid_camera_distance(center, fine_dir, original_camera_pos)
                    cam_pos_fine = center + t_fine * fine_dir

                    if not (0 < cam_pos_fine[2] < 1.5 * z0):
                        continue

                    if (
                        ray_hits_kdtree(cam_pos_fine, center, cloud_clean_kdtree, cloud_clean_pcd) or
                        ray_hits_kdtree(cam_pos_fine, [cam_pos_fine[0], cam_pos_fine[1], 0], cloud_clean_kdtree, cloud_clean_pcd) or
                        ray_hits_kdtree(cam_pos_fine, [cam_pos_fine[0], cam_pos_fine[1], 0], target_kdtree, target_pcd)
                    ):
                        continue

                    return {
                        'location': cam_pos_fine.tolist(),
                        'rotation_euler': look_at_rotation(cam_pos_fine, center).tolist()
                    }
            else:
                # æ²¡æœ‰ refineï¼Œä½†å·²ç»æ˜¯ç¬¬ä¸€ä¸ªåˆæ³• coarse è§†è§’äº†
                print(f"ğŸŸ¢ ä½¿ç”¨ coarse è§†è§’ï¼ˆæ—  refineï¼‰ï¼š{cam_pos.tolist()}")
                return {
                    'location': cam_pos.tolist(),
                    'rotation_euler': look_at_rotation(cam_pos, center).tolist()
                }
    if best_coarse_cam is not None:
        print(f"ğŸŸ¡ ä½¿ç”¨ç²—æ‰°åŠ¨ fallback è§†è§’ï¼š{best_coarse_cam.tolist()}")
        return {
            'location': best_coarse_cam.tolist(),
            'rotation_euler': look_at_rotation(best_coarse_cam, center).tolist()
        }

    t_fallback = compute_valid_camera_distance(center, normal_mean, original_camera_pos)
    cam_pos_fallback = center + t_fallback * normal_mean
    print(f"ğŸ”´ æ‰€æœ‰æ–¹å‘éæ³•ï¼Œä½¿ç”¨ä¸»æ³•å‘ fallback è§†è§’ã€‚")
    print(f"    â¤ fallback_cam = {cam_pos_fallback.tolist()}")
    return {
        'location': cam_pos_fallback.tolist(),
        'rotation_euler': look_at_rotation(cam_pos_fallback, center).tolist()
    }




# ================== å¯è§æ€§è®¡ç®—å‡½æ•° ==================
def compute_visible_points(model_pcd, env_pcd, cam):
    points_world_orig = np.asarray(model_pcd.points)
    points_env = np.asarray(env_pcd.points)

    fx, fy = cam["intrinsic"]["fx"], cam["intrinsic"]["fy"]
    cx, cy = cam["intrinsic"]["cx"], cam["intrinsic"]["cy"]
    width, height = cam["intrinsic"]["width"], cam["intrinsic"]["height"]
    T_world2cam = np.array(cam["extrinsic"])

    # ======= è‡ªåŠ¨åŠ å¯† =======
    pcd_tree = o3d.geometry.KDTreeFlann(model_pcd)
    distances = []
    for i in range(len(points_world_orig)):
        [_, idx, dists] = pcd_tree.search_knn_vector_3d(model_pcd.points[i], 6)
        distances.extend(np.sqrt(dists[1:]))
    mean_dist = np.mean(distances)
    target_spacing = mean_dist / 2.0

    density = 5
    r = np.arange(-density // 2 + 1, density // 2 + 1)
    offsets = np.array([[dx, dy, dz] for dx in r for dy in r for dz in r]) * target_spacing / (density // 2)

    expanded_model = (points_world_orig[:, None, :] + offsets[None, :, :]).reshape(-1, 3)
    orig_indices = np.repeat(np.arange(len(points_world_orig)), len(offsets))

    expanded_env = (points_env[:, None, :] + offsets[None, :, :]).reshape(-1, 3)

    # åˆå¹¶è†¨èƒ€åçš„æ¨¡å‹å’Œç¯å¢ƒç‚¹
    points_all = np.vstack([expanded_env, expanded_model])

    # ======= æŠ•å½±ä¸é®æŒ¡å‰”é™¤ =======
    points_homo = np.concatenate([points_all, np.ones((len(points_all), 1))], axis=1)
    points_cam = (T_world2cam @ points_homo.T).T[:, :3]
    z_cam = points_cam[:, 2]
    valid = z_cam < 0
    points_cam = points_cam[valid]
    z_cam = -z_cam[valid]
    u = (fx * points_cam[:, 0] / -points_cam[:, 2] + cx).astype(np.int32)
    v = (fy * points_cam[:, 1] / -points_cam[:, 2] + cy).astype(np.int32)
    depth = np.full((height, width), np.inf, dtype=np.float32)
    index_map = np.full((height, width), -1, dtype=np.int32)
    valid_indices = np.nonzero(valid)[0]

    for i in range(len(z_cam)):
        if 0 <= u[i] < width and 0 <= v[i] < height:
            if z_cam[i] < depth[v[i], u[i]]:
                depth[v[i], u[i]] = z_cam[i]
                index_map[v[i], u[i]] = valid_indices[i]

    # ======= æŠ•ç¥¨æ‰¾åŸå§‹ç‚¹å¯è§æ€§ =======
    visible_expanded_indices = np.unique(index_map[index_map >= 0])

    model_offset = len(expanded_env)
    visible_model_indices = visible_expanded_indices[visible_expanded_indices >= model_offset]
    visible_model_indices = visible_model_indices.astype(np.int32)

    # æ˜ å°„ï¼švisible_model_indices ä¸­æ˜¯å“ªäº›è†¨èƒ€æ¨¡å‹ç‚¹è¢«çœ‹åˆ°ï¼ˆç›¸å¯¹äº expanded_model èµ·ç‚¹ï¼‰

    # æ‰¾å‡ºå“ªäº›è†¨èƒ€æ¨¡å‹ç‚¹æ˜¯æœ‰æ•ˆçš„ï¼ˆç›¸æœºå‰æ–¹ï¼‰
    valid_model_mask = valid[model_offset:]
    assert valid_model_mask.shape[0] == orig_indices.shape[0], "âŒ é•¿åº¦ä¸åŒ¹é…ï¼Œæ¨¡å‹è†¨èƒ€ç‚¹æ•°å¼‚å¸¸"

    # æ˜ å°„è†¨èƒ€ç´¢å¼• â†’ valid ä¸­å‹ç¼©åçš„ç´¢å¼•ï¼ˆåªå¯¹ valid ä¸º True çš„ç‚¹ä¿ç•™ä½ç½®ï¼‰
    valid_index_map = -np.ones(valid_model_mask.shape[0], dtype=np.int32)
    valid_index_map[valid_model_mask] = np.arange(np.sum(valid_model_mask))

    # å¯è§è†¨èƒ€ç‚¹çš„ç›¸å¯¹ç´¢å¼•ï¼ˆç›¸å¯¹äº expanded_modelï¼‰
    relative_indices = visible_model_indices - model_offset

    # åœ¨å‹ç¼©åçš„ valid ç´¢å¼•æ˜ å°„ä¸­æŸ¥æ‰¾è¿™äº›å¯è§ç‚¹çš„ä½ç½®
    compressed_indices = valid_index_map[relative_indices]

    # è¿‡æ»¤æ‰ -1ï¼ˆå³ invalidï¼‰
    valid_mask = compressed_indices >= 0
    visible_orig_ids_all = orig_indices[compressed_indices[valid_mask]]


    vote_count = Counter(visible_orig_ids_all)

    min_visible_votes = len(offsets) * 0.15  # é˜ˆå€¼ï¼Œæ”¯æŒå‚æ•°åŒ–
    visible_mask = np.array([vote_count[i] >= min_visible_votes for i in range(len(points_world_orig))])

    visible_orig_ids = np.where(visible_mask)[0]
    coverage = len(visible_orig_ids) / len(points_world_orig)
    print(f"ğŸ“Š å½“å‰è§†è§’è¦†ç›–ç‡: {coverage:.2%} ({len(visible_orig_ids)} / {len(points_world_orig)})")

    return visible_orig_ids

def visualize_visibility_sequence(model_pcd, env_pcd, visible_ids_sequence):
    """
    å¯è§†åŒ–å¤šè½®æ–°å¢å¯è§ç‚¹ï¼š
    - æ¯è½®é¢œè‰²ä¸åŒï¼ˆçº¢ã€æ©™ã€é»„ã€ç»¿ã€è“ã€ç´«ï¼‰
    - ç¯å¢ƒç‚¹ä¸ºç°è‰²
    - æœªè¢«è§‚æµ‹çš„ç‚¹ä¸æ˜¾ç¤º

    å‚æ•°:
        model_pcd: åŸå§‹ç‰©ä½“ç‚¹äº‘ (o3d.geometry.PointCloud)
        env_pcd: ç¯å¢ƒç‚¹äº‘ (o3d.geometry.PointCloud)
        visible_ids_sequence: List[np.ndarray[int]]
            - æ¯è½®æ–°å¢çš„å¯è§ç‚¹ç´¢å¼•ï¼ˆéç´¯è®¡ï¼‰
    """
    points_world_orig = np.asarray(model_pcd.points)
    color_list = [
        [1.0, 0.0, 0.0],  # çº¢
        [1.0, 0.5, 0.0],  # æ©™
        [1.0, 1.0, 0.0],  # é»„
        [0.0, 1.0, 0.0],  # ç»¿
        [0.0, 0.5, 1.0],  # è“
        [0.5, 0.0, 1.0],  # ç´«
    ]

    pcds = []

    # ç¯å¢ƒç‚¹äº‘ï¼šç°è‰²
    env_pcd.paint_uniform_color([0.5, 0.5, 0.5])
    pcds.append(env_pcd)

    for i, visible_ids in enumerate(visible_ids_sequence):
        color = color_list[i % len(color_list)]
        pcd_visible = o3d.geometry.PointCloud()
        pcd_visible.points = o3d.utility.Vector3dVector(points_world_orig[visible_ids])
        pcd_visible.paint_uniform_color(color)
        pcds.append(pcd_visible)

    o3d.visualization.draw_geometries(
        pcds,
        window_name="NBV Visibility Sequence (Redâ†’Purple = Earlierâ†’Later)",
        width=1280, height=720,
    )

def blender_camera_extrinsic(cam_pos, lookat, up_vector=np.array([0, 0, 1])):
    """
    ç”Ÿæˆ Blender ç›¸æœºå¤–å‚çŸ©é˜µï¼ˆT_world2camï¼‰ï¼Œç”¨äºå¯è§æ€§è®¡ç®—ç­‰ã€‚

    å‚æ•°:
        cam_pos: ç›¸æœºä½ç½®ï¼Œnp.array([x, y, z])
        lookat: ç›¸æœºè§‚å¯Ÿç‚¹ï¼Œnp.array([x, y, z])
        up_vector: ç›¸æœºçš„ä¸–ç•Œä¸Šæ–¹å‘ï¼ˆé»˜è®¤ Z è½´æœä¸Šï¼‰

    è¿”å›:
        4x4 å¤–å‚çŸ©é˜µ (np.ndarray)
    """
    # Zè½´: ä»ç›¸æœºæŒ‡å‘ç›®æ ‡
    forward = cam_pos - lookat
    forward = forward / np.linalg.norm(forward)

    # Xè½´: å³æ–¹å‘
    right = np.cross(up_vector, forward)
    right = right / np.linalg.norm(right)

    # Yè½´: ä¸Šæ–¹å‘ï¼ˆé‡æ–°è®¡ç®—ï¼‰
    up = np.cross(forward, right)

    # ç›¸æœºæ—‹è½¬çŸ©é˜µ
    R = np.stack([right, up, forward], axis=1)  # åˆ—å‘é‡æ˜¯å³ã€ä¸Šã€å‰

    # è½¬ä¸ºç›¸æœºåæ ‡ç³» â†’ ç›¸å½“äºé€†å˜æ¢ï¼ˆè½¬ç½® + å¹³ç§»ï¼‰
    R_inv = R.T
    t_inv = -R_inv @ cam_pos

    # æ„é€ å¤–å‚çŸ©é˜µ
    T = np.eye(4)
    T[:3, :3] = R_inv
    T[:3, 3] = t_inv
    return T




# é¢„è®¾è·¯å¾„å’Œæ–‡ä»¶ä½ç½®ï¼ˆæ ¹æ®ä½ çš„ Blender è¾“å‡ºç›®å½•ï¼‰
BASE = Path("D:/NBV/nbv_simulation/results")
PLY_PATH = BASE / "model_full_transformed.ply"
ENV_PATH = BASE / "cloud_clean.ply"
CAM_PATH = BASE / "camera.json"

# åŠ è½½ç‚¹äº‘å’Œåˆå§‹ç›¸æœºé…ç½®
model_pcd = o3d.io.read_point_cloud(str(PLY_PATH))
env_pcd = o3d.io.read_point_cloud(str(ENV_PATH))
cloud_clean_pcd = env_pcd  # ç”¨äºé®æŒ¡æ£€æµ‹
target_pcd = model_pcd     # è‹¥ä¸ºè£å‰ªç›®æ ‡ï¼Œä¹Ÿå¯æ›¿æ¢ä¸ºå­é›†

with open(CAM_PATH, "r") as f:
    cam = json.load(f)  

# === åˆå§‹åŒ– ===
points = np.asarray(model_pcd.points)
total_ids = set(range(len(points)))
lookat = np.mean(points, axis=0)  # æ‰€æœ‰è§†è§’ç»Ÿä¸€æœå‘ç›®æ ‡ä¸­å¿ƒ

# ä½¿ç”¨ Blender ç›¸æœºå¤–å‚ç®—ç¬¬ä¸€è½®å¯è§ç‚¹ï¼ˆä¸ä¿å­˜è¿™ä¸ªç›¸æœºï¼‰
visible_ids = compute_visible_points(model_pcd, env_pcd, cam)
visible_ids = np.array(visible_ids, dtype=int)

# åˆå§‹åŒ–æ‰€æœ‰å·²çŸ¥å¯è§ç‚¹
all_visible_ids = set(visible_ids)
visible_ids_sequence = [visible_ids]  # æ¯ä¸€è½®æ–°å¢ç‚¹ï¼Œç”¨äºå¯è§†åŒ–
camera_poses = []                     # åªè®°å½• NBV ç”Ÿæˆçš„ç›¸æœº
visualize_visibility_sequence(model_pcd, env_pcd, visible_ids_sequence)

# ç›¸æœºä½ç½®åˆå§‹åŒ–ä¸º Blender ç›¸æœºçš„ä½ç½®
T_world2cam = np.array(cam["extrinsic"])
R = T_world2cam[:3, :3]
t = T_world2cam[:3, 3]
cam_pos = -R.T @ t

# === å¼€å§‹ NBV è¿­ä»£ ===
max_rounds = 5
for i in range(max_rounds - 1):  # ç¬¬ä¸€è½®æ˜¯ Blender æä¾›ï¼Œåç»­æœ€å¤š 4 æ¬¡
    # åˆ¤æ–­å‰©ä½™æœªè§‚æµ‹ç‚¹
    unobserved_ids = np.array(list(total_ids - all_visible_ids))
    if len(unobserved_ids) == 0:
        print(f"âœ… æ‰€æœ‰ç‚¹å·²è¢«è§‚æµ‹ï¼Œç»ˆæ­¢äºç¬¬ {i+1} è½®ã€‚")
        break

    unobserved_points = points[unobserved_ids]

    # è°ƒç”¨ find_best_viewpoint è·å–ä¸‹ä¸€æœ€ä½³è§†è§’
    next_cam = find_best_viewpoint(
        unobserved_points,
        cloud_clean_pcd,
        target_pcd,
        cam_pos
    )
    save_blender_camera_position(
    view_result=next_cam,
    save_dir="D:/NBV/nbv_simulation/results/VisualCameras",
    idx=i
    )  
    print(f"å·²ç»ä¿å­˜{i+2}å·ç›¸æœºä¿¡æ¯")
    # æ›´æ–°ç›¸æœºä½ç½®ï¼ˆç”¨äºä¸‹ä¸€è½®è¿­ä»£ï¼‰
    cam_pos = np.array(next_cam["location"])
    camera_poses.append(next_cam)  # è®°å½• NBV ç”Ÿæˆçš„ç›¸æœºä¿¡æ¯

    extrinsic = blender_camera_extrinsic(cam_pos, lookat)
    cam_struct = {
    "intrinsic": cam["intrinsic"],   # ä¿æŒåŸå§‹ç›¸æœºçš„å†…å‚
    "extrinsic": extrinsic.tolist()  # å½“å‰æ–°è§†è§’çš„å¤–å‚
    }

    # è®¡ç®—å½“å‰ç›¸æœºè§†è§’çš„å¯è§ç‚¹
    visible_ids = compute_visible_points(model_pcd, env_pcd, cam_struct)
    visible_ids = np.array(visible_ids, dtype=int)

    # æå–â€œæ–°å¢â€çš„ç‚¹
    new_ids = np.setdiff1d(visible_ids, list(all_visible_ids))
    visible_ids_sequence.append(new_ids)
    all_visible_ids.update(new_ids.tolist())

    print(f"ğŸ” Round {i+2}: æ–°å¢ {len(new_ids)} ä¸ªç‚¹ï¼Œç´¯è®¡ {len(all_visible_ids)}")
    # === å¯è§†åŒ–æœ€ç»ˆç»“æœ ===
    visualize_visibility_sequence(model_pcd, env_pcd, visible_ids_sequence)


