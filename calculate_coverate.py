from pathlib import Path
import json
import numpy as np
import open3d as o3d
from collections import Counter

# ==== ä½ çš„å¯è§æ€§è®¡ç®—å‡½æ•°ï¼ˆå®Œå…¨ä¸åŠ¨ï¼‰ ====
##from capture_depth_calculate_camera import compute_visible_points, blender_camera_extrinsic, visualize_visibility_sequence

def visualize_visibility_sequence(model_pcd, env_pcd, visible_ids_sequence):
    """
    å¯è§†åŒ–å¤šè½®æ–°å¢å¯è§ç‚¹ï¼š
    - æ¯è½®é¢œè‰²ä¸åŒï¼ˆçº¢ã€æ©™ã€é»„ã€ç»¿ã€è“ã€ç´«ï¼‰
    - ç¯å¢ƒç‚¹ä¸ºç°è‰²
    - æœªè¢«è§‚æµ‹çš„ç‚¹ä¸æ˜¾ç¤º

    å‚æ•°:
        model_pcd: åŸå§‹ç‰©ä½“ç‚¹äº‘ (o3d.geometry.PointCloud)
        env_pcd: ç¯å¢ƒç‚¹äº‘ (o3d.geometry.PointCloud)
        visible_ids_sequence: List[np.ndarray[int]]
            - æ¯è½®æ–°å¢çš„å¯è§ç‚¹ç´¢å¼•ï¼ˆéç´¯è®¡ï¼‰
    """
    points_world_orig = np.asarray(model_pcd.points)
    color_list = [
        [1.0, 0.0, 0.0],  # çº¢
        [1.0, 0.5, 0.0],  # æ©™
        [1.0, 1.0, 0.0],  # é»„
        [0.0, 1.0, 0.0],  # ç»¿
        [0.0, 0.5, 1.0],  # è“
        [0.5, 0.0, 1.0],  # ç´«
    ]

    pcds = []

    # ç¯å¢ƒç‚¹äº‘ï¼šç°è‰²
    env_pcd.paint_uniform_color([0.5, 0.5, 0.5])
    pcds.append(env_pcd)

    for i, visible_ids in enumerate(visible_ids_sequence):
        color = color_list[i % len(color_list)]
        pcd_visible = o3d.geometry.PointCloud()
        pcd_visible.points = o3d.utility.Vector3dVector(points_world_orig[visible_ids])
        pcd_visible.paint_uniform_color(color)
        pcds.append(pcd_visible)

    o3d.visualization.draw_geometries(
        pcds,
        window_name="NBV Visibility Sequence (Redâ†’Purple = Earlierâ†’Later)",
        width=1280, height=720,
    )


def blender_camera_extrinsic(cam_pos, lookat, up_vector=np.array([0, 0, 1])):
    """
    ç”Ÿæˆ Blender ç›¸æœºå¤–å‚çŸ©é˜µï¼ˆT_world2camï¼‰ï¼Œç”¨äºå¯è§æ€§è®¡ç®—ç­‰ã€‚

    å‚æ•°:
        cam_pos: ç›¸æœºä½ç½®ï¼Œnp.array([x, y, z])
        lookat: ç›¸æœºè§‚å¯Ÿç‚¹ï¼Œnp.array([x, y, z])
        up_vector: ç›¸æœºçš„ä¸–ç•Œä¸Šæ–¹å‘ï¼ˆé»˜è®¤ Z è½´æœä¸Šï¼‰

    è¿”å›:
        4x4 å¤–å‚çŸ©é˜µ (np.ndarray)
    """
    # Zè½´: ä»ç›¸æœºæŒ‡å‘ç›®æ ‡
    forward = cam_pos - lookat
    forward = forward / np.linalg.norm(forward)

    # Xè½´: å³æ–¹å‘
    right = np.cross(up_vector, forward)
    right = right / np.linalg.norm(right)

    # Yè½´: ä¸Šæ–¹å‘ï¼ˆé‡æ–°è®¡ç®—ï¼‰
    up = np.cross(forward, right)

    # ç›¸æœºæ—‹è½¬çŸ©é˜µ
    R = np.stack([right, up, forward], axis=1)  # åˆ—å‘é‡æ˜¯å³ã€ä¸Šã€å‰

    # è½¬ä¸ºç›¸æœºåæ ‡ç³» â†’ ç›¸å½“äºé€†å˜æ¢ï¼ˆè½¬ç½® + å¹³ç§»ï¼‰
    R_inv = R.T
    t_inv = -R_inv @ cam_pos

    # æ„é€ å¤–å‚çŸ©é˜µ
    T = np.eye(4)
    T[:3, :3] = R_inv
    T[:3, 3] = t_inv
    return T


def compute_visible_points(model_pcd, env_pcd, cam):
    points_world_orig = np.asarray(model_pcd.points)
    points_env = np.asarray(env_pcd.points)

    fx, fy = cam["intrinsic"]["fx"], cam["intrinsic"]["fy"]
    cx, cy = cam["intrinsic"]["cx"], cam["intrinsic"]["cy"]
    width, height = cam["intrinsic"]["width"], cam["intrinsic"]["height"]
    T_world2cam = np.array(cam["extrinsic"])

    # ======= è‡ªåŠ¨åŠ å¯† =======
    pcd_tree = o3d.geometry.KDTreeFlann(model_pcd)
    distances = []
    for i in range(len(points_world_orig)):
        [_, idx, dists] = pcd_tree.search_knn_vector_3d(model_pcd.points[i], 6)
        distances.extend(np.sqrt(dists[1:]))
    mean_dist = np.mean(distances)
    target_spacing = mean_dist / 2.0

    density = 4
    r = np.arange(-density // 2 + 1, density // 2 + 1)
    offsets = np.array([[dx, dy, dz] for dx in r for dy in r for dz in r]) * target_spacing / (density // 2)

    expanded_model = (points_world_orig[:, None, :] + offsets[None, :, :]).reshape(-1, 3)
    orig_indices = np.repeat(np.arange(len(points_world_orig)), len(offsets))

    expanded_env = (points_env[:, None, :] + offsets[None, :, :]).reshape(-1, 3)

    # åˆå¹¶è†¨èƒ€åçš„æ¨¡å‹å’Œç¯å¢ƒç‚¹
    points_all = np.vstack([expanded_env, expanded_model])

    # ======= æŠ•å½±ä¸é®æŒ¡å‰”é™¤ =======
    points_homo = np.concatenate([points_all, np.ones((len(points_all), 1))], axis=1)
    points_cam = (T_world2cam @ points_homo.T).T[:, :3]
    z_cam = points_cam[:, 2]
    valid = z_cam < 0
    points_cam = points_cam[valid]
    z_cam = -z_cam[valid]
    u = (fx * points_cam[:, 0] / -points_cam[:, 2] + cx).astype(np.int32)
    v = (fy * points_cam[:, 1] / -points_cam[:, 2] + cy).astype(np.int32)
    depth = np.full((height, width), np.inf, dtype=np.float32)
    index_map = np.full((height, width), -1, dtype=np.int32)
    valid_indices = np.nonzero(valid)[0]

    for i in range(len(z_cam)):
        if 0 <= u[i] < width and 0 <= v[i] < height:
            if z_cam[i] < depth[v[i], u[i]]:
                depth[v[i], u[i]] = z_cam[i]
                index_map[v[i], u[i]] = valid_indices[i]

    # ======= æŠ•ç¥¨æ‰¾åŸå§‹ç‚¹å¯è§æ€§ =======
    visible_expanded_indices = np.unique(index_map[index_map >= 0])

    model_offset = len(expanded_env)
    visible_model_indices = visible_expanded_indices[visible_expanded_indices >= model_offset]
    visible_model_indices = visible_model_indices.astype(np.int32)

    # æ˜ å°„ï¼švisible_model_indices ä¸­æ˜¯å“ªäº›è†¨èƒ€æ¨¡å‹ç‚¹è¢«çœ‹åˆ°ï¼ˆç›¸å¯¹äº expanded_model èµ·ç‚¹ï¼‰

    # æ‰¾å‡ºå“ªäº›è†¨èƒ€æ¨¡å‹ç‚¹æ˜¯æœ‰æ•ˆçš„ï¼ˆç›¸æœºå‰æ–¹ï¼‰
    valid_model_mask = valid[model_offset:]
    assert valid_model_mask.shape[0] == orig_indices.shape[0], "âŒ é•¿åº¦ä¸åŒ¹é…ï¼Œæ¨¡å‹è†¨èƒ€ç‚¹æ•°å¼‚å¸¸"

    # æ˜ å°„è†¨èƒ€ç´¢å¼• â†’ valid ä¸­å‹ç¼©åçš„ç´¢å¼•ï¼ˆåªå¯¹ valid ä¸º True çš„ç‚¹ä¿ç•™ä½ç½®ï¼‰
    valid_index_map = -np.ones(valid_model_mask.shape[0], dtype=np.int32)
    valid_index_map[valid_model_mask] = np.arange(np.sum(valid_model_mask))

    # å¯è§è†¨èƒ€ç‚¹çš„ç›¸å¯¹ç´¢å¼•ï¼ˆç›¸å¯¹äº expanded_modelï¼‰
    relative_indices = visible_model_indices - model_offset

    # åœ¨å‹ç¼©åçš„ valid ç´¢å¼•æ˜ å°„ä¸­æŸ¥æ‰¾è¿™äº›å¯è§ç‚¹çš„ä½ç½®
    compressed_indices = valid_index_map[relative_indices]

    # è¿‡æ»¤æ‰ -1ï¼ˆå³ invalidï¼‰
    valid_mask = compressed_indices >= 0
    visible_orig_ids_all = orig_indices[compressed_indices[valid_mask]]


    vote_count = Counter(visible_orig_ids_all)

    min_visible_votes = len(offsets) * 0.12  # é˜ˆå€¼ï¼Œæ”¯æŒå‚æ•°åŒ–
    visible_mask = np.array([vote_count[i] >= min_visible_votes for i in range(len(points_world_orig))])

    # ===== ğŸ‘‡ æ’å…¥æ³•çº¿æ–¹å‘è¿‡æ»¤é€»è¾‘ ğŸ‘‡ =====
    if model_pcd.has_normals():
        normals = np.asarray(model_pcd.normals)
        cam_pos_world = np.linalg.inv(T_world2cam)[:3, 3]  # ç›¸æœºä½ç½® in world

        vectors_to_cam = cam_pos_world - points_world_orig  # [N, 3]
        vectors_to_cam /= np.linalg.norm(vectors_to_cam, axis=1, keepdims=True)

        normals_unit = normals / np.linalg.norm(normals, axis=1, keepdims=True)
        cos_angles = np.einsum("ij,ij->i", vectors_to_cam, normals_unit)
        angles = np.arccos(np.clip(cos_angles, -1.0, 1.0))  # å¼§åº¦
        angle_threshold = np.deg2rad(100)  # å¯è°ƒï¼šè®¾ä¸º 120 æˆ– 135 å‡å¯
        direction_mask = angles < angle_threshold

        visible_mask = visible_mask & direction_mask
    # ===== ğŸ‘† æ’å…¥æ³•çº¿æ–¹å‘è¿‡æ»¤é€»è¾‘ ğŸ‘† =====

    visible_orig_ids = np.where(visible_mask)[0]

    return visible_orig_ids

# === è·¯å¾„é…ç½® ===
BASE = Path("D:/NBV/nbv_simulation/results")
CLOUD_DIR = BASE / "ReferenceCloud"
MODEL_PATH = CLOUD_DIR / "DiningTable6Seat_038_reference_points.ply"
ENV_PATH = CLOUD_DIR / "VicSideChair_038_reference_points.ply"
INIT_CAM_PATH = BASE / "camera.json"
NBV_CAM_DIR = BASE / "VisualCameras"

# === è¯»å–ç‚¹äº‘ ===
model_pcd = o3d.io.read_point_cloud(str(MODEL_PATH))
env_pcd = o3d.io.read_point_cloud(str(ENV_PATH))


# === å¯é€‰ï¼šä½“ç´ ä¸‹é‡‡æ ·ï¼ˆè°ƒè¯•é˜¶æ®µåŠ é€Ÿï¼‰
voxel_size = 0.3  
model_pcd = model_pcd.voxel_down_sample(voxel_size=voxel_size)
env_pcd = env_pcd.voxel_down_sample(voxel_size=voxel_size)




# === åˆå§‹åŒ–ç‚¹ç´¢å¼• ===
points = np.asarray(model_pcd.points)
total_ids = set(range(len(points)))
lookat = np.mean(points, axis=0)

# === ç¬¬ä¸€ä¸ªç›¸æœºï¼ˆåˆå§‹ï¼‰
with open(INIT_CAM_PATH, 'r') as f:
    cam = json.load(f)
visible_ids =  compute_visible_points(model_pcd, env_pcd, cam)

T_world2cam = np.array(cam["extrinsic"])
R = T_world2cam[:3, :3]
t = T_world2cam[:3, 3]
cam_pos = -R.T @ t  # ç”±å¤–å‚çŸ©é˜µæ¨å¾—ç›¸æœºä½ç½®



all_visible_ids = set(visible_ids)
visible_ids_sequence = [np.array(visible_ids)]
visualize_visibility_sequence(model_pcd, env_pcd, visible_ids_sequence)
# === åç»­4ä¸ª NBV ç›¸æœº
nbv_cameras = [
    NBV_CAM_DIR / "camera_00.json",
    NBV_CAM_DIR / "camera_01.json",
    NBV_CAM_DIR / "camera_02.json",
    NBV_CAM_DIR / "camera_03.json"
]

for idx, cam_path in enumerate(nbv_cameras, start=1):
    if not cam_path.exists():
        print(f"âŒ ç¼ºå¤±æ–‡ä»¶: {cam_path}")
        continue

    with open(cam_path, 'r') as f:
        cam_pose = json.load(f)

    cam_pos = np.array(cam_pose["position"])
    extrinsic = blender_camera_extrinsic(cam_pos, lookat)
    cam_struct = {
        "intrinsic": cam["intrinsic"],
        "extrinsic": extrinsic.tolist()
    }

    visible_ids =  compute_visible_points(model_pcd, env_pcd, cam_struct)
    new_ids = np.setdiff1d(visible_ids, list(all_visible_ids))
    visible_ids_sequence.append(new_ids)
    all_visible_ids.update(new_ids.tolist())

    print(f"ğŸ“· ç›¸æœº {idx}: æ–°å¢ {len(new_ids)} ä¸ªç‚¹ï¼Œç´¯è®¡ {len(all_visible_ids)}")
    visualize_visibility_sequence(model_pcd, env_pcd, visible_ids_sequence)

# === æœ€ç»ˆå¯è§†åŒ–å’Œç»Ÿè®¡ ===
coverage = len(all_visible_ids) / len(points)
print(f"\nâœ… äº”ä¸ªç›¸æœºåˆå¹¶åæ€»è¦†ç›–ç‡ï¼š{coverage:.2%}ï¼ˆ{len(all_visible_ids)} / {len(points)}ï¼‰")

